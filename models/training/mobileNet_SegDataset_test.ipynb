{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ebf3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdee23f4b70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import glob as glob\n",
    "import random\n",
    "import cv2\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import io, datasets, models, transforms\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f8bfdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/anhnguyen/Documents/testSOTACrackClassification/models/training'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f14ac14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../datasets'\n",
    "img_data_roots = [\n",
    "    '/AEL/test_img',\n",
    "    '/CFD/test_img',\n",
    "    '/CrackTree200/test_img',\n",
    "    '/CRACK500/test_img',\n",
    "    '/GAPs384/test_img'\n",
    "]\n",
    "    \n",
    "X = []\n",
    "for path in img_data_roots:\n",
    "    X.extend(glob.glob(f'{data_dir}/{path}/**/*.jpg', recursive = True))\n",
    "y = [1 for x in range(len(X))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57218c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset from dataframe\n",
    "class CrackDataset(Dataset):\n",
    "    def __init__(self, X, y, transforms=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = torch.tensor(self.y[idx],dtype=torch.long)\n",
    "        \n",
    "        img_path = self.X[idx]\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if(img.shape[:2] != (224,224)):\n",
    "            img = cv2.resize(img,(224,224))\n",
    "        \n",
    "        img = Image.fromarray(np.uint8(img)).convert('RGB')\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "            \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a92ee886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                  std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "#         normalize\n",
    "    ]),\n",
    "}\n",
    "\n",
    "#load data from a list of paths\n",
    "image_datasets = {\n",
    "    'test': \n",
    "    CrackDataset(X, y, transforms=data_transforms['validation'])\n",
    "}\n",
    "\n",
    "batch_size = 1\n",
    "num_workers = 1\n",
    "dataloaders = {\n",
    "    'test':\n",
    "    torch.utils.data.DataLoader(image_datasets['test'],\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=num_workers),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d75d077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Model define\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# device = 'cpu'\n",
    "# model = models.mobilenet_v2(pretrained=False, progress=False).to(device)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c447bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title='Confusion matrix', cmap=plt.cm.Blues, save_path = None):\n",
    "    #cm output from sklearn.confusion_matrix\n",
    "    fig, ax = plt.subplots(figsize = (5,5))\n",
    "    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            text = ax.text(j, i, np.round(cm[i, j], 2),\n",
    "                          ha=\"center\", va=\"center\", color=\"k\")\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if save_path == None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_path, facecolor = 'white')\n",
    "\n",
    "def iou(target, prediction):\n",
    "    intersection = np.logical_and(target, prediction)\n",
    "    union = np.logical_or(target, prediction)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    return iou_score\n",
    "    \n",
    "def evaluate(y_truth, y_pred, labels, \n",
    "        save_confusion_matrix_path = 'evaluation_results/sample.png', \n",
    "        save_classification_report_path = 'evaluation_results/sample.csv'\n",
    "        ): \n",
    "    labels = [str(x) for x in labels]\n",
    "\n",
    "    print('Classification Report')\n",
    "    cls_report = classification_report(y_truth, y_pred,labels = [x for x in range(len(labels))], target_names=labels)\n",
    "    if save_classification_report_path != None:\n",
    "        df = pd.DataFrame(cls_report).transpose()\n",
    "        df.to_csv(save_classification_report_path)\n",
    "    print(cls_report)\n",
    "\n",
    "    print('Confusion Matrix')\n",
    "    plot_confusion_matrix(confusion_matrix(y_truth, y_pred, normalize = 'true'), labels = labels, save_path = save_confusion_matrix_path)\n",
    "\n",
    "    \n",
    "model_save_path = \"weights\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec33f583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation model with 200 epochs on both train and val dataset\n",
    "model_trained = torch.load(f'{model_save_path}/model.pth')\n",
    "model_trained.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bda409",
   "metadata": {},
   "source": [
    "EVALUATE Other segmentation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ba7e647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e706b43d0704757b60506b20f68dabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4255 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.64      0.78      4255\n",
      "\n",
      "    accuracy                           0.64      4255\n",
      "   macro avg       0.50      0.32      0.39      4255\n",
      "weighted avg       1.00      0.64      0.78      4255\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Eval best model\n",
    "model_trained = torch.load(f'{model_save_path}/model.pth')\n",
    "model_trained.eval()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "#Inference\n",
    "model_trained.eval().to(device)\n",
    "pred_c = np.array([])\n",
    "label_c = np.array([])\n",
    "\n",
    "for inputs, labels in tqdm(dataloaders['test']):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model_trained(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    label_c = np.concatenate((label_c, labels.cpu().numpy()))\n",
    "    pred_c = np.concatenate((pred_c, preds.data.cpu().numpy()))\n",
    "labels = ['0', '1'] \n",
    "evaluate(label_c, pred_c, labels, \n",
    "        save_confusion_matrix_path = 'evaluation/segmentDataset_test_best_model.png', \n",
    "        save_classification_report_path = None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3941f1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
